{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import pandas as pd\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import requests\n",
    "import string\n",
    "import time \n",
    "\n",
    "domain = 'http://amazon.com'\n",
    "URL = 'https://www.amazon.com/s?i=beauty&bbn=11060451&rh=n%3A3760911%2Cn%3A11055981%2Cn%3A11060451%2Cp_n_target_audience_browse-bin%3A405780011&dc&page=148&fst=as%3Aoff&qid=1599987405&rnid=405778011&ref=sr_pg_147'\n",
    "driver = webdriver.Chrome(executable_path ='/Applications/chromedriver')\n",
    "driver.get(URL)\n",
    "subhtml = driver.page_source\n",
    "soup = BeautifulSoup(subhtml, \"html.parser\")\n",
    "\n",
    "while True:\n",
    "    \n",
    "    for i in soup.find_all(class_='a-section a-spacing-medium'):\n",
    "        \n",
    "        #go inside product page\n",
    "     \n",
    "        nextlink = domain + i.find(class_='a-link-normal a-text-normal')['href']\n",
    "        print(nextlink)\n",
    "        driver.get(nextlink)\n",
    "        temp = driver.page_source\n",
    "        soup = BeautifulSoup(temp, \"html.parser\")\n",
    "\n",
    "        #1. extract brand name\n",
    "        try:\n",
    "            brand = soup.find_all(id='bylineInfo')[0].text\n",
    "            if 'Visit' in brand:\n",
    "                brand = re.match('(?:.{0,10})(.+)(?:\\s.+)', brand).group(1)\n",
    "                print(brand)\n",
    "            elif 'Brand:' in brand:\n",
    "                brand = re.match('^Brand\\:\\s(.+)', brand).group()\n",
    "            else:\n",
    "                print('NO brand name')\n",
    "        except:\n",
    "            brand = np.nan\n",
    "            print('NO Brand')\n",
    "            \n",
    "        \n",
    "        #2. extract product name        \n",
    "        try:   \n",
    "            product_name = soup.find(id='productTitle').text.replace('\\n','').replace(brand+' ','')\n",
    "            print(product_name)\n",
    "        except:\n",
    "            product_name = np.nan\n",
    "            print('NO product_name')\n",
    "            \n",
    "        #3. extract category\n",
    "        try:\n",
    "            cate = soup.find(id='wayfinding-breadcrumbs_feature_div').find_all(class_='a-list-item')[6].text.replace('\\n','')\n",
    "            print('Categorie: '+cate)\n",
    "        except:\n",
    "            cate = np.nan\n",
    "            print('NO CATE') \n",
    "\n",
    "            \n",
    "        #4. extract original price /rmb covert to hkd!\n",
    "        try:\n",
    "            original_price = soup.find(class_='priceBlockStrikePriceString a-text-strike').text\n",
    "            print('original price(USD): '+original_price)\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            try:\n",
    "                original_price = soup.find(class_='a-size-medium a-color-price priceBlockBuyingPriceString').text\n",
    "                print('original price(USD): '+original_price)\n",
    "            except:\n",
    "                original_price = np.nan\n",
    "                print('NO original_price')\n",
    "                \n",
    "               \n",
    "                \n",
    "        #5. extract discounted price /rmb covert to hkd!\n",
    "        try:\n",
    "            discounted_price = soup.find(class_='a-size-medium a-color-price priceBlockBuyingPriceString').text\n",
    "            print('discounted_price(USD): '+discounted_price)\n",
    "            \n",
    "        except:\n",
    "            \n",
    "            try:\n",
    "                discounted_price = original_price\n",
    "                print('discounted_price(USD): '+discounted_price)\n",
    "            except:\n",
    "                discounted_price = np.nan\n",
    "                print('NO discounted_price')\n",
    "                \n",
    "        #6. extract promotiona message\n",
    "        try:\n",
    "            promotion_message = soup.find_all(id='promoPriceBlockMessage_feature_div')[1].text.replace('\\n','').replace('  Shop items','')\n",
    "            print('Promotion Message: '+promotion_message)\n",
    "        except:\n",
    "            try:\n",
    "                promotion_message = soup.find(id='vpcButton').text.replace('\\n','')\n",
    "                print('Promotion Message: '+promotion_message)\n",
    "            except:\n",
    "                promotion_message = np.nan\n",
    "                print('NO Promo')\n",
    " \n",
    "        #7. extract no of reviews(ratings)\n",
    "        try:\n",
    "            no_of_reviews = soup.find(id='acrCustomerReviewText').text.replace(',',\"\")\n",
    "            no_of_reviews = re.match('(\\d+)', no_of_reviews).group()\n",
    "            print('no_of_reviews: '+no_of_reviews)\n",
    "        except:\n",
    "            no_of_reviews = np.nan\n",
    "            print('NO no_of_reviews')\n",
    "\n",
    "\n",
    "        #8. extract ratings    \n",
    "        try:\n",
    "            ratings = soup.find(class_='a-icon-alt').text\n",
    "            ratings = re.match('(\\d\\.?\\d?)(?:\\s.+)', ratings).group(1)\n",
    "            print('ratings: ' + ratings)\n",
    "        except:\n",
    "            ratings = np.nan\n",
    "            print('NO ratings')\n",
    "        \n",
    "        df = df.append({'Brand':brand,\n",
    "                        'Product Name':product_name,\n",
    "                        'Category':cate,\n",
    "                        'Original Price':original_price,\n",
    "                        'Discounted Price':discounted_price,\n",
    "                        'No. of Reviews':no_of_reviews,\n",
    "                        'Ratings':ratings,\n",
    "                        'Promotion Message':promotion_message}, ignore_index = True)\n",
    "\n",
    "        \n",
    "    #going back to main page after looping    \n",
    "    temp = driver.get(URL) \n",
    "    subhtml = driver.page_source\n",
    "    soup = BeautifulSoup(subhtml, \"html.parser\")\n",
    "\n",
    "    #going to the next page\n",
    "    temp2 = soup.find(class_='a-last').a['href']\n",
    "    URL = domain + temp2\n",
    "    driver.get(URL)\n",
    "    subhtml = driver.page_source\n",
    "    soup = BeautifulSoup(subhtml, \"html.parser\")\n",
    "\n",
    "# df.to_csv(\"amazon.csv\")"
   ]
  }
 ]
}